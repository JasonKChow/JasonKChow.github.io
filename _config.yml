# Site
repository: sproogen/resume-theme
favicon: images/favicon.ico

# Content configuration version
version: 2

# Personal info
name: Jason Chow
title: Computational Cognitive Scientist
email: me@jasonc.how
# website: https://jasonc.how

# Dark Mode (true/false/never)
darkmode: never

# Social links
# twitter_username: facespics
github_username:  jasonkchow
# stackoverflow_username: "00000001"
# dribbble_username: jekyll
# facebook_username: jekyll
# flickr_username: jekyll
# instagram_username: jameswgrant
linkedin_username: jason-chow-66719827a
# xing_username: jekyll
# pinterest_username: jekyll
# youtube_username: globalmtb
# googleplus_username: +jekyll
# orcid_username: 0000-0001-5439-471X

# Additional icon links
additional_links:
- title: Google Scholar
  icon: fas fa-book
  url: https://scholar.google.com/citations?user=dxEzLKAAAAAJ&hl=en
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"

# About Section
# about_title: About Me
about_profile_image: images/profile.jpg
about_content: | # this will include new lines to allow paragraphs
  I am a Computational Cognitive Scientist specializing in leveraging machine 
  learning and AI to understand human perception and decision-making. I develop 
  machine learning models inspired by principles in cognitive psychology to 
  extract unique insights from high-dimensional data. My skillset enables me to 
  distill complex human data into actionable takeaways, providing a unique 
  window into data.

I am proficient in Python, R, and JavaScript. I have extensive experience with 
libraries and technologies for machine learning such as Tensorflow, PyTorch, 
and Scikit-learn. My expertise also includes data visualization with D3.js, 
statistical analysis with Tidyverse, lavaan, BayesFactor. In my side-projects, 
I've flexed my wider technical skills in creating end-to-end consumer-facing 
projects creating an ETL pipeline, efficient data APIs, and interactive data 
visualization dashboards, serving 20K+ users.

  See my **[resume](https://jasonc.how/pdfs/resumeEng-JasonKChow.pdf)** for more details!

content:
  - title: Education # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        border: weak
        title: Vanderbilt University
        caption: 2018 - 2024
        sub_title: PhD Psychological Sciences
        description: | # this will include new lines to allow paragraphs
          * Developed scalable framework to reliably measure representational variability across deep neural networks due to differences in model attributes (e.g., model architecture, training dataset, and training regime) across 700+ models and 9 datasets.
          * Distilled insights from high-dimensional large-scale analysis (e.g., INDSCAL, hierarchical clustering) of deep neural network models to efficiently instantiate parametric model manipulations across a set of 100 new networks to systematically vary representations to model individual differences in object recognition ability.
          * Implemented psychologically-inspired transfer learning DNN architecture improving a multi-task classification accuracy by 3%
          * Designed, optimized, and validated new measures of object recognition ability in vision, haptics, and audition using hand-designed trials and data-driven automated techniques resulting in high reliability with faster tests (25% reduction in test time).
          * Created internal R package to perform statistical analysis/visualization of multivariate individual differences data using confirmatory factor analysis and Bayesian hypothesis testing, resulting in 7 first-author publications.

  - title: Portfolio
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        border: weak
        title: RaidedGW2
        sub_title: Guild Wars 2 Data Tool
        link: https://observablehq.com/@jasonkchow/raidreport
        link_text: Demo link
        additional_links:
          - title: Backend Repo
            icon: fas fa-code
            url: https://github.com/Raided-pro/RaidedGW2
          - title: Discord Bot Repo
            icon: fab fa-discord
            url: https://github.com/Raided-pro/RaidedBot
        description: | # this will include new lines to allow paragraphs
          The game Guild Wars 2 has rich combat logs that can be parsed on a 
          per fight basis. These logs include information on teams of players
          and their performance in individual fights. I built a Discord bot 
          using Python to connect to my backend server that collects and parses
          logs to store data in a MySQL database. The backend server also acts 
          as an API for my frontend web app built with D3.js in Observable 
          Notebooks to provide an interactive way to explore the data. 

          While log parsers are common in the Guild Wars 2 community, it lacks
          a central repository to track performance week over week and compare
          people's performance in the same fights. This project aimed to fill
          this gap at a small scale for my friends. I focused on providing an
          clean and intuitive interface both from the Discord bot and the online
          web app that is easy to understand while still having a lot of options.

      - layout: left
        border: weak
        title: RaidedGW2
        sub_title: Guild Wars 2 Data Tool
        link: https://observablehq.com/@jasonkchow/raidreport
        link_text: Demo link
        additional_links:
          - title: Backend Repo
            icon: fas fa-code
            url: https://github.com/Raided-pro/RaidedGW2
          - title: Discord Bot Repo
            icon: fab fa-discord
            url: https://github.com/Raided-pro/RaidedBot
        description: | # this will include new lines to allow paragraphs
          The game Guild Wars 2 has rich combat logs that can be parsed on a 
          per fight basis. These logs include information on teams of players
          and their performance in individual fights. I built a Discord bot 
          using Python to connect to my backend server that collects and parses
          logs to store data in a MySQL database. The backend server also acts 
          as an API for my frontend web app built with D3.js in Observable 
          Notebooks to provide an interactive way to explore the data. 

          While log parsers are common in the Guild Wars 2 community, it lacks
          a central repository to track performance week over week and compare
          people's performance in the same fights. This project aimed to fill
          this gap at a small scale for my friends. I focused on providing an
          clean and intuitive interface both from the Discord bot and the online
          web app that is easy to understand while still having a lot of options.

      - layout: left
        title: RaidedCrow
        sub_title: Crowfall Log Parser
        link: https://observablehq.com/d/df02f3f553b6b0c6
        link_text: Demo link
        description: | # this will include new lines to allow paragraphs
          The short-lived game Crowfall could produce combat logs but they were
          poorly formatted and there lacked a convenient way to parse and 
          organize the information. Further, the community had a culture of 
          keeping their strategies a secret so privacy was a concern. I built 
          this tool with D3.js in Observable Notebooks to parse and organize 
          this data completely locally in the browser. 

          With this project, I focused on making the tool to display as much
          information as possible while still being useful even at a glance. I 
          wanted users to be able to quickly glean summary information and then
          be able to dig into the exact breakdowns of the data.

  - title: Research Interests
    layout: list
    content: 
      - layout: top-middle
        border: weak
        title: Individual differences in object recognition ability
        description: | # this will include new lines to allow paragraphs

          <div style="text-align:center"><img src="https://i.imgur.com/BfYTOZ7.png"/></div>

          In this line of research, I have developed completely new tests of 
          object recognition ability, applying psychometrics techniques to 
          confidently measure this ability in haptic and auditory perception. Using
          multivariate statistical techniques like confirmatory factor analysis, I 
          found that visual and haptic object recognition share about 25% of their
          variance. Interestingly, between visual and auditory object recognition 
          ability, there was an almost perfect correlation across modalities. The 
          robust relationships remain even when controlling for possible third 
          factors like general intelligence, working memory, and low-level visual 
          ability. These findings suggests that object recognition ability taps into 
          common perceptual mechanisms that extends across modalities.  

          **Representative Publications:**
          * **Chow, J.K.**, Palmeri, T.J. & Gauthier, I. (2024). Distinct but 
          related abilities for visual and haptic object recognition. *Psychon 
          Bull Rev*. https://doi.org/10.3758/s13423-024-02471-x
          * **Chow, J.K.**, Palmeri, T. J., Pluck, G., & Gauthier, I. (2023). 
          Evidence for an amodal domain general object recognition ability. 
          *Cognition*, 238, 105542.
      - layout: top-middle
        title: Modeling Individual Differences in Perception with DNNs
        description: | # this will include new lines to allow paragraphs

          <div style="text-align:center"><img src="https://i.imgur.com/zdo3ZGz.png"/></div>

          We know that there are reliable individual differences in perceptual 
          abilities but why they exist remains elusive. I am interested in using 
          the latest deep neural networks to model individual differences and ask
          what factors best account for these differences. As modeling individual
          differences with deep neural networks is a relatively new approach, I have
          worked to determine the best ways to measure differences between deep 
          neural networks, directly comparing similarity metrics used in machine
          learning, psychology, and neuroscience. In parallel, I have begun work on
          determining which factors in deep neural networks are the best to 
          manipulate when the goal is to model individual differences. To do this, I
          sampled from a large space of deep neural networks to efficiently test 
          which combination of factors result in the most consistent variations. 

          **Representative Publications:**
          * **Chow, J.** & Palmeri, T. (2022). Manipulating and Measuring Variation 
          in DNN Representations. Poster presented at: *2022 Conference on Cognitive 
          Computational Neuroscience*; Aug 2022; San Francisco, CA


# Footer
footer_show_references: false
# references_title: https://jasonc.how/pdfs/CV-JasonKChow.pdf

# Build settings
remote_theme: sproogen/resume-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag
